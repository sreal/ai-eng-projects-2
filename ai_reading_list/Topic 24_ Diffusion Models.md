# Topic 24: Diffusion Models

1. **Introduction to Diffusion Models**: https://www.assemblyai.com/blog/diffusion-models-for-machine-learning-introduction

2. **Lilian Weng's deep but readable overview of diffusion principles and advances**: https://lilianweng.github.io/posts/2021-07-11-diffusion-models/

3. **Demystifying Diffusion Models**: narrative explanation and code from scratch: https://goyalpramod.github.io/blogs/demysitifying_diffusion_models/

4. **Stable Diffusion Got Supercharged**: Two Minute Papers summary of ControlNet advancements: https://www.youtube.com/watch?v=1RvZWHtFXuY

5. **Hugging Face tutorial with full annotated implementation**: https://huggingface.co/blog/annotated-diffusion

6. **Latent Diffusion Models**: the research behind Stable Diffusion using latent space denoising: https://arxiv.org/abs/2112.10752

7. **Google AI blog on Imagen and Parti architectures**: https://blog.google/technology/research/how-ai-creates-photorealistic-images-from-text/

8. **DreamBooth: Fine-Tuning Text-to-Image Diffusion Models** (official Google project for personalizing models): https://dreambooth.github.io/

9. **Tutorial for custom fine-tuning with DreamBooth**: https://huggingface.co/blog/dreambooth

10. **Beginner-friendly guide with setup and token tips for DreamBooth**: https://www.analyticsvidhya.com/blog/2023/09/dreambooth-stable-diffusion-for-custom-images/

11. **ControlNet (adding Control to Stable Diffusion's Image Generation)**: Explains sketch/pose/edge guidance: https://blog.segmind.com/what-is-stable-diffusion-controlnet/

12. **T2I-Adapter: What is it and How Does it Work?** A lightweight alternative to ControlNet for guided diffusion: https://medium.com/@utkarsh135/t2i-adapter-what-is-it-and-how-does-it-work-23b42ba99ed4

13. **Identifying AI-Generated Images with SynthID**: DeepMind's watermarking for diffusion-generated content: https://deepmind.google/discover/blog/identifying-ai-generated-images-with-synthid/

14. **OpenAI paper showing diffusion outperforming GANs**: https://arxiv.org/abs/2105.05233

15. **NVIDIA's EDM paper improving diffusion efficiency**: https://arxiv.org/abs/2206.00364

16. **Stable Diffusion XL**: https://arxiv.org/abs/2307.01952

17. **LoRA for Stable Diffusion**: lightweight personalization technique using low-rank adapters: https://stable-diffusion-art.com/lora/

18. **Runway Gen-2**: diffusion-powered text-to-video system for short video generation: https://research.runwayml.com/gen2

19. **DALLÂ·E 3**: OpenAI's latest image generation model with integrated prompt understanding and filters: https://openai.com/dall-e-3

20. **Consistency Models**: faster one-step generation alternative to diffusion processes: https://arxiv.org/abs/2303.01469

21. **Hugging Face Diffusers Library** (open-source toolkit for building, training, and using diffusion models): https://github.com/huggingface/diffusers

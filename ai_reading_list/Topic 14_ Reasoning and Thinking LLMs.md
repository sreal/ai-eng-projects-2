# Topic 14: Reasoning and Thinking LLMs

1. **Chain-of-Thought Prompting**: https://arxiv.org/abs/2201.11903

2. **Zero-shot CoT**: https://arxiv.org/abs/2205.11916

3. **Tree-of-Thoughts**: exploring multiple reasoning hypotheses: https://arxiv.org/abs/2305.10601

4. **Self-Consistency**: https://arxiv.org/abs/2203.11171

5. **Graph of Thoughts**: graph-structured planning over intermediate "thoughts": https://arxiv.org/abs/2308.09687

6. **ReAct**: interleave reasoning with tool use and actions: https://arxiv.org/abs/2210.03629

7. **Language Agent Tree Search**: combines planning, acting, and reasoning with MCTS: https://arxiv.org/abs/2310.04406

8. **Program-of-Thoughts**: generates code as the reasoning trace, then executes it: https://arxiv.org/abs/2211.12588

9. **Plan-and-Solve prompting**: plan first, then carry out the steps: https://arxiv.org/abs/2305.04091

10. **Self-Ask prompting**: break questions into sub-questions with optional search: https://arxiv.org/pdf/2210.03350

11. **CRITIC**: self-correct by using tools to critique and revise outputs: https://openreview.net/forum?id=Sx038qxjek

12. **Self-Refine**: iterative self-feedback to improve an initial answer: https://arxiv.org/abs/2303.17651

13. **Reflexion**: agents that write reflections to learn from mistakes across trials: https://arxiv.org/abs/2303.11366

14. **STaR**: self-taught reasoner that bootstraps rationales for fine-tuning: https://arxiv.org/abs/2203.14465

15. **Quiet-STaR**: learn internal "thoughts" during continued pretraining for better reasoning: https://arxiv.org/abs/2403.09629

16. **OpenAI o1 methods overview**: on training models to "think before answering": https://openai.com/index/learning-to-reason-with-llms/

17. **Process supervision overview**: for improving mathematical reasoning with step-level signals: https://forum.openai.com/public/videos/improving-mathematical-reasoning-with-process-supervision-2023-07-26

18. **Let's Verify Step by Step**: train verifiers to check each reasoning step: https://openreview.net/forum?id=v8L0pN6EOi

19. **Step-level reward models as navigators**: use PRMs to steer search at inference time: https://openreview.net/forum?id=RSQL6xvUYW

20. **Multi-step Problem Solving Through a Verifier**: use a verifier to guide and validate multi-step solutions: https://aclanthology.org/2024.findings-emnlp.429.pdf

21. **OpenAI reasoning best practices**: practical tips for using o-series reasoning models: https://platform.openai.com/docs/guides/reasoning-best-practices

22. **OpenAI o3 and o4-mini**: overview of newest reasoning models and use cases: https://openai.com/index/introducing-o3-and-o4-mini/

23. **Google Gemini "thinking" guide**: API usage for models with internal thinking: https://ai.google.dev/gemini-api/docs/thinking

24. **DeekSeek-R1 paper**: https://arxiv.org/abs/2501.12948

25. **Scaling LLM Test-Time Compute Optimally can be More Effective than Scaling Model Parameters**: https://arxiv.org/abs/2408.03314

26. **Improve Mathematical Reasoning in Language Models by Automated Process Supervision**: https://arxiv.org/abs/2406.06592v1

27. **Training Language Models to Self-Correct via Reinforcement Learning**: https://arxiv.org/abs/2409.12917

28. **Towards System 2 Reasoning in LLMs: Learning How to Think With Meta Chain-of-Thought**: https://arxiv.org/abs/2501.04682
